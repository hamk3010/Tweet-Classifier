{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Tutorial for Generative Adversarial Nets\n",
    "This tutorial introduces Generative Adversarial Networks on MNIST.\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import numpy.random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import os, sys, socket\n",
    "gpuid = 1 \n",
    "os.environ['THEANO_FLAGS'] = \"mode=FAST_RUN,device=gpu%d,floatX=float32,force_device=True,base_compiledir=~/.theano/%s_gpu%d\" % (gpuid, socket.gethostname(), gpuid)\n",
    "\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "from IPython import display\n",
    "\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Input, Convolution2D, Flatten, merge\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import SGD, Adam\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original X shape (60000, 28, 28)\n",
      "Original Y shape (60000,)\n",
      "Training X matrix shape (60000, 784)\n",
      "Testing X matrix shape (10000, 784)\n",
      "Training Y matrix shape (60000, 10)\n",
      "Testing Y matrix shape (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "# Load data.\n",
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "print(\"Original X shape\", X_train.shape)\n",
    "print(\"Original Y shape\", Y_train.shape)\n",
    "\n",
    "# Reshape data.\n",
    "X_train = X_train.reshape(60000, 784)\n",
    "X_test  = X_test.reshape(10000, 784)\n",
    "X_train = X_train.astype('float32') \n",
    "X_test  = X_test.astype('float32')\n",
    "X_train /= 255 # Original data is uint8 (0-255). Scale it to range [0,1].\n",
    "X_test  /= 255\n",
    "print(\"Training X matrix shape\", X_train.shape)\n",
    "print(\"Testing X matrix shape\", X_test.shape)\n",
    "    \n",
    "# Represent the targets as one-hot vectors: e.g. 2 -> [0, 0, 1, 0, 0, 0, 0, 0, 0].\n",
    "nb_classes = 10\n",
    "Y_train = np_utils.to_categorical(Y_train, nb_classes)\n",
    "Y_test  = np_utils.to_categorical(Y_test, nb_classes)\n",
    "print(\"Training Y matrix shape\", Y_train.shape)\n",
    "print(\"Testing Y matrix shape\", Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Keras Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model\n",
    "def define_generator(ndense=1, nhid=100, lr=1e-3, act='relu', mom=0.9, dropout=0.0, input_shape=20):\n",
    "    # Define 'generator' that predicts sig vs bg from features.\n",
    "    input_shape = input_shape # Number of inputs to generator (random numbers)\n",
    "    output_shape= 784\n",
    "    ndense      = 2\n",
    "    nhid        = 100\n",
    "    act         = 'relu'\n",
    "    input       = Input(shape=(input_shape,), name='input')\n",
    "    x           = input\n",
    "    for i in range(ndense):\n",
    "        x = Dense(output_dim=nhid, activation=act, init='glorot_normal')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "    output    = Dense(output_dim=output_shape, activation='sigmoid', init='glorot_normal', name='output')(x)\n",
    "    generator = Model(input, output)\n",
    "    opt       = Adam(lr=lr, beta_1=mom) \n",
    "    generator.compile(loss='binary_crossentropy', optimizer=opt)\n",
    "    return generator\n",
    "\n",
    "def define_discriminator(ndense=1, nhid=100, act='relu', lr=1e-3, mom=0.9, decay=0.0, dropout=0.0):\n",
    "    # Define 'discriminator' that predicts whether input is generated vs. real.\n",
    "    input_shape = 784 \n",
    "    output_shape= 1 \n",
    "    ndense      = ndense\n",
    "    nhid        = nhid\n",
    "    act         = act\n",
    "    input       = Input(shape=(input_shape,))\n",
    "    x           = input\n",
    "    for i in range(ndense):\n",
    "        x = Dense(output_dim=nhid, activation=act, init='glorot_normal')(x)\n",
    "    output = Dense(output_dim=output_shape, activation='sigmoid', init='glorot_normal')(x)\n",
    "    discriminator = Model(input, output)\n",
    "    #opt       = Adam(lr=lr, beta_1=mom) \n",
    "    opt = SGD(lr=lr,momentum=mom,decay=decay)\n",
    "    discriminator.compile(loss='binary_crossentropy', optimizer=opt)\n",
    "    return discriminator\n",
    "\n",
    "def plot_loss(history):\n",
    "    plt.figure(1)\n",
    "    plt.clf()\n",
    "    for k in history:\n",
    "        plt.plot(history[k], label=k)\n",
    "    plt.legend()\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('')\n",
    "    #plt.show()\n",
    "    \n",
    "def plot_gen(generator, input_shape):\n",
    "    noisebatch = np.random.uniform(-1, 1, size=[10, input_shape])\n",
    "    generated  = generator.predict(noisebatch)\n",
    "    plt.figure(2, figsize=(14,5))\n",
    "    plt.clf()\n",
    "    for i in range(10):\n",
    "        plt.subplot(2,5, i+1)\n",
    "        plt.imshow(generated[i,:].reshape(28,28), cmap='gray', interpolation='none', vmin=0.0, vmax=1.0)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([]) \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hamzakhan/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:12: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=100, kernel_initializer=\"glorot_normal\")`\n",
      "  if sys.path[0] == '':\n",
      "/Users/hamzakhan/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:14: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", name=\"output\", units=784, kernel_initializer=\"glorot_normal\")`\n",
      "  \n",
      "/Users/hamzakhan/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:30: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"tanh\", units=20, kernel_initializer=\"glorot_normal\")`\n",
      "/Users/hamzakhan/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:31: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"glorot_normal\")`\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Variable batch_normalization_1/moving_mean/biased already exists, disallowed. Did you mean to set reuse=True in VarScope? Originally defined at:\n\n  File \"/Users/hamzakhan/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 1001, in moving_average_update\n    x, value, momentum, zero_debias=True)\n  File \"/Users/hamzakhan/anaconda3/lib/python3.6/site-packages/keras/layers/normalization.py\", line 185, in call\n    self.momentum),\n  File \"/Users/hamzakhan/anaconda3/lib/python3.6/site-packages/keras/engine/topology.py\", line 617, in __call__\n    output = self.call(inputs, **kwargs)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-9c818be205d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mdiscriminator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefine_discriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndense\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnhid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mact\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'tanh'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmom\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmomdisc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdecay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecay\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#, clipnorm=clipnorm)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mgan\u001b[0m           \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmomgen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclipnorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclipnorm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, layers, name)\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 411\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    465\u001b[0m                 \u001b[0;31m# and create the node connecting the current layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m                 \u001b[0;31m# to the input layer we just created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 467\u001b[0;31m                 \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    468\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inbound_nodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_tensors\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m             \u001b[0;31m# Actually call the layer, collecting output(s), mask(s), and shape(s).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 617\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    618\u001b[0m             \u001b[0moutput_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, mask)\u001b[0m\n\u001b[1;32m   2076\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_tensor_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2077\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2078\u001b[0;31m             \u001b[0moutput_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_internal_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2079\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput_tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36mrun_internal_graph\u001b[0;34m(self, inputs, masks)\u001b[0m\n\u001b[1;32m   2227\u001b[0m                                 \u001b[0;32mif\u001b[0m \u001b[0;34m'mask'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2228\u001b[0m                                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mask'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomputed_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2229\u001b[0;31m                             \u001b[0moutput_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_to_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomputed_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2230\u001b[0m                             output_masks = _to_list(layer.compute_mask(computed_tensor,\n\u001b[1;32m   2231\u001b[0m                                                                        computed_mask))\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/layers/normalization.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training)\u001b[0m\n\u001b[1;32m    183\u001b[0m         self.add_update([K.moving_average_update(self.moving_mean,\n\u001b[1;32m    184\u001b[0m                                                  \u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m                                                  self.momentum),\n\u001b[0m\u001b[1;32m    186\u001b[0m                          K.moving_average_update(self.moving_variance,\n\u001b[1;32m    187\u001b[0m                                                  \u001b[0mvariance\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mmoving_average_update\u001b[0;34m(x, value, momentum)\u001b[0m\n\u001b[1;32m    999\u001b[0m     \"\"\"\n\u001b[1;32m   1000\u001b[0m     return moving_averages.assign_moving_average(\n\u001b[0;32m-> 1001\u001b[0;31m         x, value, momentum, zero_debias=True)\n\u001b[0m\u001b[1;32m   1002\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1003\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/moving_averages.py\u001b[0m in \u001b[0;36massign_moving_average\u001b[0;34m(variable, value, decay, zero_debias, name)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mdecay\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mzero_debias\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0mupdate_delta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_zero_debias\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0mupdate_delta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mvariable\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdecay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/moving_averages.py\u001b[0m in \u001b[0;36m_zero_debias\u001b[0;34m(unbiased_var, value, decay)\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0mlocal_step_initializer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m       biased_var = variable_scope.get_variable(\n\u001b[0;32m--> 180\u001b[0;31m           \"biased\", initializer=biased_initializer, trainable=False)\n\u001b[0m\u001b[1;32m    181\u001b[0m       local_step = variable_scope.get_variable(\n\u001b[1;32m    182\u001b[0m           \u001b[0;34m\"local_step\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter)\u001b[0m\n\u001b[1;32m   1047\u001b[0m       \u001b[0mcollections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaching_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m       \u001b[0mpartitioner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1049\u001b[0;31m       use_resource=use_resource, custom_getter=custom_getter)\n\u001b[0m\u001b[1;32m   1050\u001b[0m get_variable_or_local_docstring = (\n\u001b[1;32m   1051\u001b[0m     \"\"\"%s\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(self, var_store, name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter)\u001b[0m\n\u001b[1;32m    946\u001b[0m           \u001b[0mcollections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaching_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m           \u001b[0mpartitioner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m           use_resource=use_resource, custom_getter=custom_getter)\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m   def _get_partitioned_variable(self,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter)\u001b[0m\n\u001b[1;32m    354\u001b[0m           \u001b[0mreuse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreuse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m           \u001b[0mcaching_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpartitioner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m           validate_shape=validate_shape, use_resource=use_resource)\n\u001b[0m\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m   def _get_partitioned_variable(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36m_true_getter\u001b[0;34m(name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource)\u001b[0m\n\u001b[1;32m    339\u001b[0m           \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m           \u001b[0mcaching_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m           use_resource=use_resource)\n\u001b[0m\u001b[1;32m    342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcustom_getter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36m_get_single_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, partition_info, reuse, trainable, collections, caching_device, validate_shape, use_resource)\u001b[0m\n\u001b[1;32m    651\u001b[0m                          \u001b[0;34m\" Did you mean to set reuse=True in VarScope? \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    652\u001b[0m                          \"Originally defined at:\\n\\n%s\" % (\n\u001b[0;32m--> 653\u001b[0;31m                              name, \"\".join(traceback.format_list(tb))))\n\u001b[0m\u001b[1;32m    654\u001b[0m       \u001b[0mfound_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_vars\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    655\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfound_var\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Variable batch_normalization_1/moving_mean/biased already exists, disallowed. Did you mean to set reuse=True in VarScope? Originally defined at:\n\n  File \"/Users/hamzakhan/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 1001, in moving_average_update\n    x, value, momentum, zero_debias=True)\n  File \"/Users/hamzakhan/anaconda3/lib/python3.6/site-packages/keras/layers/normalization.py\", line 185, in call\n    self.momentum),\n  File \"/Users/hamzakhan/anaconda3/lib/python3.6/site-packages/keras/engine/topology.py\", line 617, in __call__\n    output = self.call(inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from keras.layers.normalization import BatchNormalization\n",
    "num_epochs  = 10000  *3\n",
    "plt_frq     = 500\n",
    "batchsize   = 100\n",
    "input_shape = 10 # Number of random inputs to generator.\n",
    "lr          = .01\n",
    "momgen      = 0.\n",
    "momdisc     = 0.\n",
    "clipnorm    = 1.\n",
    "decay     =   1e-5\n",
    "\n",
    "generator     = define_generator(ndense=4, nhid=100, act='tanh', input_shape=input_shape)\n",
    "discriminator = define_discriminator(ndense=2, nhid=20, act='tanh', lr=lr*10, mom=momdisc,decay=decay) #, clipnorm=clipnorm)\n",
    "discriminator.trainable = False\n",
    "gan           = Sequential(layers=[generator, discriminator])\n",
    "gan.compile(loss='binary_crossentropy', optimizer=SGD(lr=lr, momentum=momgen, decay=decay, clipnorm=clipnorm))\n",
    "      \n",
    "history = defaultdict(list)\n",
    "for epoch in tqdm(range(num_epochs)):  \n",
    "\n",
    "    # Generate images.\n",
    "    noisebatch = np.random.uniform(-1, 1, size=[batchsize,input_shape])\n",
    "    generated  = generator.predict(noisebatch)\n",
    "\n",
    "    # Update discriminator.\n",
    "    databatch  = X_train[np.random.randint(0,X_train.shape[0], size=batchsize), :]    \n",
    "    X          = np.concatenate([databatch, generated])\n",
    "    T          = np.concatenate([np.ones((databatch.shape[0],)), np.zeros((generated.shape[0],))]) # Real:1, fake:0\n",
    "    discriminator.trainable = True\n",
    "    d_loss  = discriminator.train_on_batch(X,T)\n",
    "    history[\"d_loss\"].append(d_loss)\n",
    "    \n",
    "    # Update generator.\n",
    "    noisebatch = np.random.uniform(-1, 1, size=[batchsize,input_shape])\n",
    "    T          = np.ones((noisebatch.shape[0],)) # Try to generate data that looks real.\n",
    "    discriminator.trainable = False\n",
    "    g_loss = gan.train_on_batch(noisebatch, T)\n",
    "    history[\"g_loss\"].append(g_loss)\n",
    "    \n",
    "    # Updates plots\n",
    "    if epoch % plt_frq == plt_frq - 1:\n",
    "        display.clear_output(wait=True)\n",
    "        display.display(plt.gcf())\n",
    "        plot_loss(history)\n",
    "        plot_gen(generator, input_shape=input_shape)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attempt 2: Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9b0ced7810>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEPCAYAAACukxSbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9b0ced7810>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxMAAAElCAYAAACf5r/JAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9ad34c3a10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10000/10000 [01:34<00:00, 105.59it/s]\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Reshape\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import UpSampling2D\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.layers.core import Flatten\n",
    "from keras.optimizers import SGD\n",
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "#from PIL import Image\n",
    "import argparse\n",
    "import math\n",
    "\n",
    "def generator_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(input_dim=100, output_dim=1024))\n",
    "    model.add(Activation('tanh'))\n",
    "    model.add(Dense(128*7*7))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('tanh'))\n",
    "    model.add(Reshape((128, 7, 7), input_shape=(128*7*7,)))\n",
    "    model.add(UpSampling2D(size=(2, 2)))\n",
    "    model.add(Convolution2D(64, 5, 5, border_mode='same'))\n",
    "    model.add(Activation('tanh'))\n",
    "    model.add(UpSampling2D(size=(2, 2)))\n",
    "    model.add(Convolution2D(1, 5, 5, border_mode='same'))\n",
    "    model.add(Activation('tanh'))\n",
    "    return model\n",
    "\n",
    "\n",
    "def discriminator_model():\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(\n",
    "                        64, 5, 5,\n",
    "                        border_mode='same',\n",
    "                        input_shape=(1, 28, 28)))\n",
    "    model.add(Activation('tanh'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Convolution2D(128, 5, 5))\n",
    "    model.add(Activation('tanh'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024))\n",
    "    model.add(Activation('tanh'))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    return model\n",
    "\n",
    "def generator_containing_discriminator(generator, discriminator):\n",
    "    model = Sequential()\n",
    "    model.add(generator)\n",
    "    discriminator.trainable = False\n",
    "    model.add(discriminator)\n",
    "    return model\n",
    "\n",
    "num_epochs  = 10000 \n",
    "plt_frq     = 500 \n",
    "batchsize   = 100\n",
    "input_shape = 10 # Number of random inputs to generator.\n",
    "lr          = .01\n",
    "momgen      = 0.0\n",
    "momdisc     = 0.0\n",
    "clipnorm    = 1.\n",
    "decay     =   1e-5\n",
    "\n",
    "discriminator_on_generator = generator_containing_discriminator(generator, discriminator)\n",
    "d_optim = SGD(lr=0.0005, momentum=0.9, nesterov=True)\n",
    "g_optim = SGD(lr=0.0005, momentum=0.9, nesterov=True)\n",
    "generator.compile(loss='binary_crossentropy', optimizer=\"SGD\")\n",
    "discriminator_on_generator.compile(loss='binary_crossentropy', optimizer=g_optim)\n",
    "discriminator.trainable = True\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer=d_optim)\n",
    "        \n",
    "history = defaultdict(list)\n",
    "for epoch in tqdm(range(num_epochs)):  \n",
    "\n",
    "    # Generate images.\n",
    "    noisebatch = np.random.uniform(-1, 1, size=[batchsize,input_shape])\n",
    "    generated  = generator.predict(noisebatch)\n",
    "\n",
    "    # Update discriminator.\n",
    "    databatch  = X_train[np.random.randint(0,X_train.shape[0], size=batchsize), :]    \n",
    "    X          = np.concatenate([databatch, generated])\n",
    "    T          = np.concatenate([np.ones((databatch.shape[0],)), np.zeros((generated.shape[0],))]) # Real:1, fake:0\n",
    "    discriminator.trainable = True\n",
    "    d_loss  = discriminator.train_on_batch(X,T)\n",
    "    history[\"d_loss\"].append(d_loss)\n",
    "    \n",
    "    # Update generator.\n",
    "    noisebatch = np.random.uniform(-1, 1, size=[batchsize,input_shape])\n",
    "    T          = np.ones((noisebatch.shape[0],)) # Try to generate data that looks real.\n",
    "    discriminator.trainable = False\n",
    "    g_loss = gan.train_on_batch(noisebatch, T)\n",
    "    history[\"g_loss\"].append(g_loss)\n",
    "    \n",
    "    # Updates plots\n",
    "    if epoch % plt_frq == plt_frq - 1:\n",
    "        display.clear_output(wait=True)\n",
    "        display.display(plt.gcf())\n",
    "        plot_loss(history)\n",
    "        plot_gen(generator, input_shape=input_shape) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
